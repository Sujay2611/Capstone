{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('virus_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=copy.copy(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset['SlNo'],dataset['FarmerEduaction'],dataset['FarmerAge'],dataset['GPSCordinate'],dataset['Zone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del q['Temperature'],q['pH'],q['Salinity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(q.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = q.iloc[:,0:37]\n",
    "y_label = q.iloc[:, 38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = q.corr().abs()\n",
    "\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del q['CrabFench'],q['FootBath'],q['Aerator'],q['Reservoir'],q['LimitedAccess'],q['WaterSource_IndirectNatural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(q.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=q.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['VirusDetected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_target=q.iloc[:,0:31]\n",
    "target=q.iloc[:,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=1, max_depth=10)\n",
    "df=pd.get_dummies(non_target)\n",
    "model.fit(df,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[-12:]  # top 12 features\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=[features[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i in k:\n",
    "    a.append(q[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset=q[['SourceOfFingerling',\n",
    " 'CanalDepth_ft',\n",
    " 'WaterSource_DirectNatural',\n",
    " 'PeriodOfFallow',\n",
    " 'FeedType',\n",
    " 'StockingAge_Days',\n",
    " 'WaterExchangeFrequency',\n",
    " 'InvolveWithShrimpFarming',\n",
    " 'StockingDensity_PL/40MeterSquare',\n",
    " 'GherDepth_ft',\n",
    " 'Area_ha',\n",
    " 'PreviousPrevalence(%)',\n",
    "         'VirusDetected']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "split_ratio=0.70\n",
    "\n",
    "def split_train_test(data, split_ratio, train, test):\n",
    "    for index,row in data.iterrows():\n",
    "        if(random.random()>split_ratio):\n",
    "            test.append(row)\n",
    "        else:\n",
    "            train.append(row)\n",
    "        \n",
    "train=[]\n",
    "test=[]\n",
    "\n",
    "split_train_test(subset, split_ratio, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=[]\n",
    "ytrain=[]\n",
    "for x in train:\n",
    "    xtrain.append(x[:12])\n",
    "    ytrain.append(x[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest=[]\n",
    "ytest=[]\n",
    "for x in test:\n",
    "    xtest.append(x[:12])\n",
    "    ytest.append(x[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "DT = DecisionTreeClassifier(max_depth=4)\n",
    "DT = DT.fit(xtrain,ytrain)\n",
    "pred_test = DT.predict(xtest)\n",
    "pred_train = DT.predict(xtrain)\n",
    "print(\"Accuracy for Decision tree, Random Forest, KNN and Logistic Regression models\\n\")\n",
    "print(\"Decision tree\")\n",
    "print(\"Train Accuracy:\",metrics.accuracy_score(ytrain, pred_train))\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(ytest, pred_test))\n",
    "print(\"\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier(max_depth=4)\n",
    "RFC = RFC.fit(xtrain,ytrain)\n",
    "pred_test = RFC.predict(xtest)\n",
    "pred_train = RFC.predict(xtrain)\n",
    "print(\"Random forest classifier\")\n",
    "print(\"Train Accuracy:\",metrics.accuracy_score(ytrain, pred_train))\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(ytest, pred_test))\n",
    "print(\"\")\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "KNN = KNN.fit(xtrain,ytrain)\n",
    "pred_test = KNN.predict(xtest)\n",
    "pred_train = KNN.predict(xtrain)\n",
    "print(\"K nearest neighbour\")\n",
    "print(\"Train Accuracy:\",metrics.accuracy_score(ytrain, pred_train))\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(ytest, pred_test))\n",
    "print(\"\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(solver='liblinear')\n",
    "LR = LR.fit(xtrain,ytrain)\n",
    "pred_test = LR.predict(xtest)\n",
    "pred_train = LR.predict(xtrain)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Train Accuracy:\",metrics.accuracy_score(ytrain, pred_train))\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(ytest, pred_test))\n",
    "print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=subset.iloc[:,0:12]\n",
    "b=subset.iloc[:,12]\n",
    "\n",
    "DTSKF = DecisionTreeClassifier(max_depth=4)\n",
    "RFCSKF = RandomForestClassifier(max_depth=4)\n",
    "KNNSKF = KNeighborsClassifier(n_neighbors=3)\n",
    "LRSKF = LogisticRegression(solver='liblinear')\n",
    "\n",
    "dt_train_accuracy=[]\n",
    "dt_test_accuracy=[]\n",
    "\n",
    "rf_train_accuracy=[]\n",
    "rf_test_accuracy=[]\n",
    "\n",
    "knn_train_accuracy=[]\n",
    "knn_test_accuracy=[]\n",
    "\n",
    "lr_train_accuracy=[]\n",
    "lr_test_accuracy=[]\n",
    "\n",
    "for train_index, test_index in skf.split(a,b):\n",
    "    #print(train_index,test_index)\n",
    "    x_train=[]\n",
    "    x_test=[]\n",
    "    y_train=[]\n",
    "    y_test=[]\n",
    "    for i in train_index:\n",
    "        x_train.append(a.iloc[i])\n",
    "        y_train.append(b.iloc[i])\n",
    "        \n",
    "    for i in test_index:\n",
    "        x_test.append(a.iloc[i])\n",
    "        y_test.append(b.iloc[i])\n",
    "        \n",
    "\n",
    "    DTSKF = DTSKF.fit(x_train,y_train)\n",
    "    pred_train = DTSKF.predict(x_train)\n",
    "    pred_test = DTSKF.predict(x_test)\n",
    "    #print(\"Train Accuracy:\",metrics.accuracy_score(ytrain, pred_train))\n",
    "    #print(\"Test Accuracy:\",metrics.accuracy_score(ytest, pred_test))\n",
    "    dt_train_accuracy.append(metrics.accuracy_score(y_train, pred_train))\n",
    "    dt_test_accuracy.append(metrics.accuracy_score(y_test, pred_test))\n",
    "    \n",
    "    RFCSKF = RFCSKF.fit(x_train,y_train)\n",
    "    pred_train = RFCSKF.predict(x_train)\n",
    "    pred_test = RFCSKF.predict(x_test)\n",
    "    #print(\"Train Accuracy:\",metrics.accuracy_score(ytrain, pred_train))\n",
    "    #print(\"Test Accuracy:\",metrics.accuracy_score(ytest, pred_test))\n",
    "    rf_train_accuracy.append(metrics.accuracy_score(y_train, pred_train))\n",
    "    rf_test_accuracy.append(metrics.accuracy_score(y_test, pred_test))\n",
    "    \n",
    "    KNNSKF = KNNSKF.fit(x_train,y_train)\n",
    "    pred_train = KNNSKF.predict(x_train)\n",
    "    pred_test = KNNSKF.predict(x_test)\n",
    "    #print(\"Train Accuracy:\",metrics.accuracy_score(ytrain, pred_train))\n",
    "    #print(\"Test Accuracy:\",metrics.accuracy_score(ytest, pred_test))\n",
    "    knn_train_accuracy.append(metrics.accuracy_score(y_train, pred_train))\n",
    "    knn_test_accuracy.append(metrics.accuracy_score(y_test, pred_test))\n",
    "    \n",
    "    LRSKF = LRSKF.fit(x_train,y_train)\n",
    "    pred_train = LRSKF.predict(x_train)\n",
    "    pred_test = LRSKF.predict(x_test)\n",
    "    #print(\"Train Accuracy:\",metrics.accuracy_score(ytrain, pred_train))\n",
    "    #print(\"Test Accuracy:\",metrics.accuracy_score(ytest, pred_test))\n",
    "    lr_train_accuracy.append(metrics.accuracy_score(y_train, pred_train))\n",
    "    lr_test_accuracy.append(metrics.accuracy_score(y_test, pred_test))\n",
    "    \n",
    "\n",
    "print(\"Accuracy for Decision tree, Random Forest Classifier, KNN and Logistic Regression models using stratified K fold cross validation\\n\")\n",
    "print(\"Decision tree\")\n",
    "print(\"training accuracy : \"+str(sum(dt_train_accuracy)/4))\n",
    "print(\"testing accuracy  : \"+str(sum(dt_test_accuracy)/4))\n",
    "print(\"\")\n",
    "print(\"Random forest classifier\")\n",
    "print(\"training accuracy : \"+str(sum(rf_train_accuracy)/4))\n",
    "print(\"testing accuracy  : \"+str(sum(rf_test_accuracy)/4))\n",
    "print(\"\")\n",
    "print(\"K nearest neighbour\")\n",
    "print(\"training accuracy : \"+str(sum(knn_train_accuracy)/4))\n",
    "print(\"testing accuracy  : \"+str(sum(knn_test_accuracy)/4))\n",
    "print(\"\")\n",
    "print(\"Logistic Regression\")\n",
    "print(\"training accuracy : \"+str(sum(lr_train_accuracy)/4))\n",
    "print(\"testing accuracy  : \"+str(sum(lr_test_accuracy)/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without stratified k fold\n",
    "\n",
    "# Decision tree\n",
    "dt_train_accuracy=[81.0, 77.7, 84.5, 77.3, 84.1]\n",
    "dt_test_accuracy=[57.6, 60.5, 62.0, 70.0, 57.3]\n",
    "\n",
    "# Random forest classifier\n",
    "rf_train_accuracy=[85.1, 87.8, 86.8, 85.8, 86.7]\n",
    "rf_test_accuracy=[71.7, 75.0, 67.2, 68.5, 70.6]\n",
    "\n",
    "# KNN\n",
    "knn_train_accuracy=[74.3, 77.0, 76.5, 77.3, 75.9]\n",
    "knn_test_accuracy=[63.5, 69.7, 50.0, 67.1, 52.0]\n",
    "\n",
    "# Logistic Regression\n",
    "lr_train_accuracy=[70.9, 69.4, 73.7, 73.0, 66.4]\n",
    "lr_test_accuracy=[56.4, 67.1, 55.4, 61.4, 66.6]\n",
    "\n",
    "instances=[1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Decision Tree\")\n",
    "plt.plot(instances,dt_train_accuracy)\n",
    "plt.plot(instances,dt_test_accuracy)\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel(\"instances\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(['train accuracy', 'test accuracy'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Random Forest Classifier\")\n",
    "plt.plot(instances,rf_train_accuracy)\n",
    "plt.plot(instances,rf_test_accuracy)\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel(\"instances\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(['train accuracy', 'test accuracy'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"KNN\")\n",
    "plt.plot(instances,knn_train_accuracy)\n",
    "plt.plot(instances,knn_test_accuracy)\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel(\"instances\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(['train accuracy', 'test accuracy'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Logistic Regression\")\n",
    "plt.plot(instances,lr_train_accuracy)\n",
    "plt.plot(instances,lr_test_accuracy)\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel(\"instances\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(['train accuracy', 'test accuracy'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Stratified K fold\n",
    "\n",
    "# Decision tree\n",
    "dt_skf_train_accuracy=[81.2, 81.2, 81.2, 81.2, 81.2]\n",
    "dt_skf_test_accuracy=[60.0, 61.3, 60.4, 60.4, 60.4]\n",
    "\n",
    "# Random forest classifier\n",
    "rf_skf_train_accuracy=[84.8, 84.4, 83.9, 85.6, 84.8]\n",
    "rf_skf_test_accuracy=[68.6, 69.5, 69.5, 68.7, 69.0]\n",
    "\n",
    "# KNN\n",
    "knn_skf_train_accuracy=[76.2, 76.2, 76.2, 76.2, 76.2]\n",
    "knn_skf_test_accuracy=[56.6, 56.6, 56.7, 56.6, 56.6]\n",
    "\n",
    "# Logistic Regression\n",
    "lr_skf_train_accuracy=[70.5, 70.5, 70.5, 70.5, 70.5]\n",
    "lr_skf_test_accuracy=[61.8, 61.8, 61.8, 61.8, 61.8]\n",
    "\n",
    "instances=[1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Decision Tree\")\n",
    "plt.plot(instances,dt_skf_train_accuracy)\n",
    "plt.plot(instances,dt_skf_test_accuracy)\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel(\"instances\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(['train accuracy', 'test accuracy'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Random Forest Classifier\")\n",
    "plt.plot(instances,rf_skf_train_accuracy)\n",
    "plt.plot(instances,rf_skf_test_accuracy)\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel(\"instances\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(['train accuracy', 'test accuracy'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"KNN\")\n",
    "plt.plot(instances,knn_skf_train_accuracy)\n",
    "plt.plot(instances,knn_skf_test_accuracy)\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel(\"instances\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(['train accuracy', 'test accuracy'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Logistic Regression\")\n",
    "plt.plot(instances,lr_skf_train_accuracy)\n",
    "plt.plot(instances,lr_skf_test_accuracy)\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel(\"instances\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(['train accuracy', 'test accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion\n",
    "# 1. Random forest classifier is the best model in terms of both test and train accuracy.\n",
    "# 2. K nearest neighbour performs worst among all the 4 models for disease prediction.\n",
    "# 3. Adding stratified K fold validation reduces the variance of train/test accuracies for all 4 models.\n",
    "# 4. The gap between train accuracy and testing accuracy is least for logistic regression indicating that LR model \n",
    "#    works well with unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(n):\n",
    "    if(n==0.0 or n==0):\n",
    "        return \"No Disease\"\n",
    "    else:\n",
    "        return \"Disease\"\n",
    "\n",
    "\n",
    "instance_list=[]\n",
    "import random\n",
    "for x,y in subset.iteritems():\n",
    "    if(x!='VirusDetected'):\n",
    "        if(y.dtypes==\"int\"):\n",
    "            instance_list.append(random.randint(min(y),max(y)))\n",
    "        else:\n",
    "            instance_list.append(random.uniform(min(y),max(y)))\n",
    "            \n",
    "single_instance=np.array(instance_list).reshape(1,-1)\n",
    "\n",
    "print(\"Prediction for simple models -\")\n",
    "print(\"Decision tree: \"+convert(DT.predict(single_instance)))\n",
    "print(\"Random forest classifier: \"+convert(RFC.predict(single_instance)))\n",
    "print(\"KNN: \"+convert(KNN.predict(single_instance)))\n",
    "print(\"Logistic Regression: \"+convert(LR.predict(single_instance)))\n",
    "\n",
    "print(\"\\nPrediction for models after adding stratified k fold cross validation -\")\n",
    "print(\"Decision tree: \"+convert(DTSKF.predict(single_instance)))\n",
    "print(\"Random forest classifier: \"+convert(RFCSKF.predict(single_instance)))\n",
    "print(\"KNN: \"+convert(KNNSKF.predict(single_instance)))\n",
    "print(\"Logistic Regression: \"+convert(LRSKF.predict(single_instance)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
